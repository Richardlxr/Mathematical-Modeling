## 一、 聚类分析概述

### 1.1 什么是聚类？
聚类分析（Clustering Analysis）是一种**无监督学习**方法。它根据“物以类聚”的原则，将背景物理意义不明的一组样本（或指标）按照某种相似性准则划分为若干类。

*   **核心逻辑**：类内个体特征极度相似，类间个体特征差异明显。
*   **与分类的区别**：分类是已知标签（如：给猫和狗的照片分类）；聚类是未知标签（如：给你一堆动物照片，让你按长相自己分堆）。
### 应用价值
#### 2.1 客户/用户细分 (Segmentation)
这是最经典的应用。通过聚类发现具有相似行为的群体。
*   **例子**：某电商根据用户的“消费频次、客单价、退货率”进行聚类。
    *   **类 A**：高频高额（核心客户） -> **策略**：发放专属优惠券。
    *   **类 B**：低频高退货（问题客户） -> **策略**：调研产品质量。

#### 2.2 区域经济/社会水平评估
在国赛 A、B 题中，常需要对省份、城市进行分级。
*   **例子**：根据 GDP、人均收入、受教育年限对全国 31 个省份聚类。
    *   **结果**：自动识别出“一线发达地区”、“中部发展地区”和“西部待开发地区”，无需人为设定阈值，更有说服力。

#### 3.3 数据预处理与异常检测
聚类可以作为其他模型的“开路先锋”。
*   **降维处理**：如果样本太多，可以先聚类，每个类选一个代表点进行后续建模。
*   **异常值剔除**：DBSCAN 算法可以将远离人群的点标记为“噪音点”。如果一个样本不属于任何簇，它极有可能是录入错误或极端异常值。


---

## 二、 相似性度量：距离与相关系数

要聚类，首先要定义什么是“近”。

### 2.1 样本之间的距离（适用于样本聚类）
设样本 $x, y$ 为 $p$ 维向量：
*   **绝对值距离（Manhattan）**：$d_1(x,y)=\sum_{k=1}^{p}|x_k-y_k|$==（每个基绝对值之差的和）==
*   **欧氏距离（Euclidean）**：$d_2(x,y)=[\sum_{k=1}^{p}|x_k-y_k|^2]^{1/2}$
*   **闵可夫斯基距离（Minkowski）**：$d_3(x,y)=[\sum_{k=1}^{p}|x_k-y_k|^q]^{1/q}$
*   **切比雪夫距离**：$d_4(x,y)=\max_{1 \le k \le p}|x_k-y_k|$

### 2.2 指标之间的相似度（适用于指标聚类）
*   **相关系数**：$\rho(X_i,X_j)$，越接近1表示两个指标变化趋势越一致。（最好选正交的指标）
*   **夹角余弦**：$r(X_i,X_j)$，衡量两个向量在方向上的相似程度。

---

## 三、 系统聚类法（Hierarchical Clustering）

系统聚类通过不断合并最近的类，最终形成一棵“聚类树”（谱系图）。

### 3.1 类与类之间的距离定义
当两个类中包含多个样本时，需要定义类间距离 $D(G_p, G_q)$：

| 方法 | 定义逻辑 | 特点 |
| :--- | :--- | :--- |
| **最短距离法** | 两类中最近两个样本的距离 | 容易产生“链状”结构，把不相似的连在一起 |
| **最长距离法** | 两类中最远两个样本的距离 | 适用于类分布比较紧凑的情况 |
| **组间平均连接法** | 两类中所有样本对距离的平均值 | 性能稳健，最常用 |
| **重心法** | 两类重心（均值点）之间的距离 | 对异常值不敏感，但合并可能导致距离非单调 |

### 3.2 谱系图（Dendrogram）
通过谱系图，我们可以直观看到样本是如何一步步合并的。在合适的距离阈值处画一条竖线，即可得到理想的分类个数。（**想分几类就分几类**）
![[Screenshot 2026-01-27 at 22.06.30.png]]
![[Screenshot 2026-01-27 at 22.06.37.png]]
![[Screenshot 2026-01-27 at 22.06.51.png]]
![[Screenshot 2026-01-27 at 22.06.57.png]]

![[Screenshot 2026-01-27 at 22.07.08.png]]

---

## 四、 动态聚类法：K-means

### 4.1 算法流程
1.  **初始化**：随机选取 $k$ 个点作为初始聚类中心。
2.  **分配**：计算每个样本到 $k$ 个中心的距离，将其归入最近的类。
3.  **更新**：重新计算每个类中所有样本的平均值（重心），作为新的类中心。
4.  **迭代**：重复步骤2和3，直到中心点不再变化或达到最大迭代次数。

### 4.2 K-means++ 的改进
为了防止初始点选得太差（比如选在一起），K-means++ 要求：**初始聚类中心之间的相互距离要尽可能远。**

---

## 五、 基于密度的聚类：DBSCAN

DBSCAN 不需要预先指定 $k$ 值，且能发现**任意形状**的簇（如：环形、S型），还能识别噪声点。

### 5.1 核心参数
*   **Epsilon ($\epsilon$)**：搜索半径。
*   **MinPts**：半径内最少需要的点数。

### 5.2 点的分类
*   **核心点**：半径 $\epsilon$ 内点数 $\ge MinPts$。
*   **边界点**：半径 $\epsilon$ 内点数 $< MinPts$，但在核心点的邻域内。
*   **噪音点**：既不是核心点也不是边界点的点。

---

### 补充笔记：聚类分析的代码实现与应用价值

在数学建模中，聚类分析不仅是用来“分类”的工具，更是**探索性数据分析（EDA）**的核心手段。

---

## 编程实现（Python 与 MATLAB）

### 1.1 Python 实现 (使用 scikit-learn)
Python 的优势在于拥有强大的机器学习库，且绘图非常漂亮。

```python
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import pandas as pd
import matplotlib.pyplot as plt

# 1. 准备数据并标准化 (必须步骤)
data = pd.read_csv('data.csv') 
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data)

# 2. 使用肘部法则确定 K 值 (计算 SSE)
sse = []
for k in range(1, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(data_scaled)
    sse.append(kmeans.inertia_)

# 3. 建模 (假设选定 K=3)
model = KMeans(n_clusters=3, init='k-means++', random_state=0)
clusters = model.fit_predict(data_scaled)

# 4. 将结果合并回原数据
data['Cluster_Label'] = clusters
```

### 1.2 MATLAB 实现
MATLAB 适合快速矩阵运算和系统聚类展示。

```matlab
% 1. 标准化数据
X = zscore(original_data);

% 2. K-means 聚类
[idx, C] = kmeans(X, 3); % 聚为3类，idx是标签，C是中心

% 3. 系统聚类 (展示谱系图)
Z = linkage(X, 'average'); % 使用平均连接法
dendrogram(Z); % 绘制谱系图
title('层次聚类谱系图');
```


---

## 三、 建模实战：如何选择最佳分类数 $K$？

在论文中，不能凭感觉说“我觉得分3类合适”，必须给出科学依据。

### 3.1 肘部法则 (Elbow Method)
通过计算**类内平方和 (SSE)** 来评估：
$$SSE = \sum_{i=1}^{k} \sum_{x \in C_i} |x - u_i|^2$$
*   **逻辑**：$k$ 越大，$SSE$ 越小。但当 $k$ 达到真实类别数后，$SSE$ 的下降幅度会迅速减小。
*   **图示**：找曲线的“拐点”，即为最佳 $K$ 值。

### 3.2 轮廓系数 (Silhouette Coefficient)
$$s(i) = \frac{b(i) - a(i)}{\max\{a(i), b(i)\}}$$
*   $a(i)$：样本到同类其他点的平均距离。
*   $b(i)$：样本到最近异类所有点的平均距离。
*   **结论**：轮廓系数越接近 **1**，说明聚类效果越完美。

---

## 四、 总结：聚类分析的“三步走”策略

| 步骤            | 动作内容                     | 核心目的                |
| :------------ | :----------------------- | :------------------ |
| **第一步：数据预处理** | 缺失值处理 +正向化+ **标准化**      | 消除指标间量纲（单位）的影响      |
| **第二步：确定分类数** | 绘制 **肘部法则图** 或 **轮廓系数图** | 为分类个数 $K$ 提供科学依据    |
| **第三步：结果分析**  | 描述各类的统计特征（均值等）           | **给每一类起个名字**，赋予物理意义 |

**一句话技巧**：在建模论文中，聚类完成后一定要有一个**特征分析表**。例如：“第一类表现为高收入低消费，命名为‘潜在储蓄型群体’”，这才是聚类分析的灵魂。